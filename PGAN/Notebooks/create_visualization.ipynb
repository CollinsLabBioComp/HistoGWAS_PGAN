{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69f13952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from limix_core.util.preprocess import gaussianize, regressOut\n",
    "import scipy.stats as st\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.linalg as la\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from mtgwas import VCTEST\n",
    "from mtgwas.utils import df_match\n",
    "\n",
    "import sys\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pil_to_tensor, to_pil_image\n",
    "import torch\n",
    "from models.progressive_gan import ProgressiveGAN as PGAN\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c63a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings \n",
    "path = '/Users/andrewdenny/Desktop/NIHPostBac/repos/HistoGWAS_PGAN/PGAN/Notebooks'\n",
    "os.chdir(path)\n",
    "outliers = 0.01\n",
    "extreme = 0.05\n",
    "np.random.seed(42)\n",
    "days = [15, 20, 25, 30]\n",
    "interpolations = 5\n",
    "analysis_group = 'TCF7L2_ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89f67029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    \n",
    "    def __init__(self, config, checkpoint, useGPU=True):\n",
    "        with open(config, 'rb') as file:\n",
    "            config = json.load(file)\n",
    "        self.pgan = PGAN(useGPU=useGPU, storeAVG=True, **config)\n",
    "        self.pgan.load(checkpoint)\n",
    "        self.netG = self.pgan.netG\n",
    "        self.device = self.pgan.device\n",
    "        \n",
    "    def forward(self, x, eps=None):\n",
    "        if eps is None:\n",
    "            eps = torch.randn(x.shape[0], 512)\n",
    "        if type(x)==np.ndarray:\n",
    "            x = torch.Tensor(x)\n",
    "        if type(eps)==np.ndarray:\n",
    "            eps = torch.Tensor(eps)\n",
    "        x = x.to(self.device)\n",
    "        eps = eps.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            out = self.netG(eps, x).data.cpu()\n",
    "            out = 0.5 * (out + 1)\n",
    "            out = torch.clip(out, 0, 1)\n",
    "        return out\n",
    "    \n",
    "def load_image_torch(path, size):\n",
    "    if type(path) in [list, np.ndarray]:\n",
    "        return torch.cat([load_image_torch(_, size) for _ in path])\n",
    "    return pil_to_tensor(Image.open(path).resize((size, size)))[None] / 255.\n",
    "\n",
    "\n",
    "def torch_imshow(x):\n",
    "    pl.imshow(x.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e97c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here False\n",
      "Average network found !\n"
     ]
    }
   ],
   "source": [
    "checkpoint = '/Users/andrewdenny/Desktop/NIHPostBac/repos/Organoid_s6_i736000.pt'\n",
    "config = '/Users/andrewdenny/Desktop/NIHPostBac/repos/HistoGWAS_PGAN/PGAN/config/config_OrganoidLocal.json'\n",
    "#checkpoint = '/Users/dennyal/Desktop/repos/Organoid_s6_i320000.pt'\n",
    "generator = Generator(config, checkpoint, useGPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62882f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = 'Organoid'\n",
    "outdir = f'visualization/{tissue}'\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee4cea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Day', 'Well', 'Well literal', 'SampleBarcode', 'Plate', 'Cell_density',\n",
      "       'Run_ID', 'MinDiameter_shape', 'MaxDiameter_shape',\n",
      "       'MeanDiameter_shape',\n",
      "       ...\n",
      "       'Eccentricity_halo', 'Orientation_halo', 'Compactness_halo',\n",
      "       'analysis_group', 'edit_id_-/-', 'edit_id_CC', 'edit_id_CT',\n",
      "       'edit_id_TT', 'edit_id_WT/-', 'edit_id_WT/WT'],\n",
      "      dtype='object', length=185)\n"
     ]
    }
   ],
   "source": [
    "dfX = pd.read_csv(\"./org_features_metadata.csv.gz\")\n",
    "dfX['SampleBarcode'] = dfX['SampleBarcode'].astype('category')\n",
    "print(dfX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f960412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trait = input(\"Trait: \")\n",
    "trait = 'MeanDiameter_shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7b637dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, day, analysis_group):\n",
    "    #Get Day\n",
    "    day_df = df[(df['Day'] == day)].copy()\n",
    "    day_df = day_df.drop(columns = ['Day', 'Plate', 'Well', 'Cell_density', 'Well literal', \"Run_ID\"])\n",
    "\n",
    "    #Mean by SampleBarcode and analysis group\n",
    "    mean_df = day_df.groupby([\"SampleBarcode\", \"analysis_group\"]).mean().reset_index()\n",
    "\n",
    "    #filter for analysis_group\n",
    "\n",
    "    day_ag_df = mean_df[mean_df['analysis_group'] == analysis_group]\n",
    "\n",
    "    # Drop tha NAs Values\n",
    "    final_df = day_ag_df.dropna(subset=[\"edit_id_-/-\", trait])\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7dc0d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_preproccess(df, trait, analysis_group):\n",
    "    if analysis_group == 'TCF7L2_ko':\n",
    "        filter_array = ['edit_id_-/-', 'edit_id_WT/-', 'edit_id_WT/WT']\n",
    "    else:\n",
    "        filter_array = ['edit_id_CC', 'edit_id_CT', 'edit_id_TT']\n",
    "\n",
    "    X = df.loc[:, filter_array].copy()\n",
    "    trait_df = pd.DataFrame(np.asarray(df[trait]))\n",
    "    y = trait_df.values\n",
    "    F = np.zeros((df.shape[0], 1))\n",
    "    return X, y, F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ce8495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(emb1, emb2, interpolations):\n",
    "    inter = np.linspace(0, 1, interpolations)[:, None]\n",
    "\n",
    "    embs = emb1 * (1 - inter) + emb2 * inter\n",
    "    eps = np.random.randn(1, 512) * np.ones([embs.shape[0], 1])\n",
    "    xinter = generator.forward(embs, eps)\n",
    "    print(xinter.shape)\n",
    "    return xinter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ffbc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization(images, trait, analysis_group):\n",
    "    n_rows = len(days)\n",
    "    n_cols = interpolations\n",
    "\n",
    "    fig = plt.figure(figsize=(38, 28), dpi=150, constrained_layout=True)\n",
    "    grid = ImageGrid(fig, 111,nrows_ncols=(n_rows, n_cols),\n",
    "        axes_pad=(0.25, 0.25))\n",
    "\n",
    "    np_images = images.numpy()\n",
    "    count = 0\n",
    "    for ax, img in zip(grid, np_images):\n",
    "        if count == 0:\n",
    "            ax.set_title('WT/WT', fontsize=50)\n",
    "        if count == 2:\n",
    "            ax.set_title('WT/-', fontsize=50)\n",
    "        if count == 4:\n",
    "            ax.set_title('-/-', fontsize=50)\n",
    "        print(ax)\n",
    "\n",
    "        if count % (interpolations) == 0:\n",
    "            print(count)\n",
    "            ax.set_ylabel(f'Day {days[count // interpolations]}', fontsize=50)\n",
    "\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "        count += 1\n",
    "    plt.suptitle(f\"{trait} {analysis_group}\", fontsize=60, y=0.995)  # adjust y to move it up/down\n",
    "    return fig\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f53cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/srj1jgcj62j9r7cm87q973940000gn/T/ipykernel_20713/1452690644.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_df = day_df.groupby([\"SampleBarcode\", \"analysis_group\"]).mean().reset_index()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 6074.30it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8631.85it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8913.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9860.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9897.36it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10291.26it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9363.54it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9599.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9464.11it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9233.88it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10051.05it/s]\n",
      "/var/folders/qy/srj1jgcj62j9r7cm87q973940000gn/T/ipykernel_20713/1452690644.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_df = day_df.groupby([\"SampleBarcode\", \"analysis_group\"]).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 8433.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 6861.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8786.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8126.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8451.66it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8171.41it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 6858.26it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 7180.18it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 6725.41it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8107.13it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8116.07it/s]\n",
      "/var/folders/qy/srj1jgcj62j9r7cm87q973940000gn/T/ipykernel_20713/1452690644.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_df = day_df.groupby([\"SampleBarcode\", \"analysis_group\"]).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 8856.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8958.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10539.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8818.97it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8819.16it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8704.04it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10091.68it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8764.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9045.10it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8010.97it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8799.55it/s]\n",
      "/var/folders/qy/srj1jgcj62j9r7cm87q973940000gn/T/ipykernel_20713/1452690644.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mean_df = day_df.groupby([\"SampleBarcode\", \"analysis_group\"]).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 10352.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9197.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9338.11it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9820.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9310.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9564.90it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 7843.78it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 7877.07it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8709.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8585.91it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8850.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_visualization() missing 2 required positional arguments: 'trait' and 'analysis_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m        xinter_grid = generate(emb1, emb2, interpolations)\n\u001b[32m     28\u001b[39m        image_acc = torch.concat((image_acc, xinter_grid))\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m fig = \u001b[43mcreate_visualization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_acc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m plt.show(fig)\n\u001b[32m     32\u001b[39m fig.savefig(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrait\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_interpolation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalysis_group\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m, dpi=\u001b[32m150\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: create_visualization() missing 2 required positional arguments: 'trait' and 'analysis_group'"
     ]
    }
   ],
   "source": [
    "image_acc = torch.zeros((0, 1, 256,256))\n",
    "for day in days:  \n",
    "       df = filter_df(dfX, day = day, analysis_group = analysis_group)\n",
    "       X,y, F = vc_preproccess(df, trait, analysis_group= analysis_group)\n",
    "       yr = regressOut(y, F)\n",
    "       Xr = regressOut(X, F)\n",
    "       vc = VCTEST()\n",
    "       res = vc.fit(Xr, yr, compute_pvals=True, normalize_X=False)\n",
    "       ystar = vc.predict_loo()\n",
    "       features =  X.to_numpy()\n",
    "       df['ystar'] = vc.predict(features).ravel()\n",
    "\n",
    "       df_embeddings = df.drop(columns = ['SampleBarcode', 'analysis_group','ystar',  'edit_id_-/-', 'edit_id_CC', 'edit_id_CT', 'edit_id_TT', 'edit_id_WT/-',\n",
    "              'edit_id_WT/WT']).copy()\n",
    "\n",
    "\n",
    "       q1, q2, Q1, Q2 = np.quantile(df['ystar'].values, [outliers, extreme, 1 - extreme, 1 - outliers])\n",
    "       Ih1 = np.logical_and(df['ystar'].values>=Q1, df['ystar'].values<=Q2)\n",
    "       Il1 = np.logical_and(df['ystar'].values>=q1, df['ystar'].values<=q2)\n",
    "\n",
    "       # interpolates\n",
    "       emb1 = df_embeddings[Il1].mean().values\n",
    "\n",
    "       emb2 = df_embeddings[Ih1].mean().values\n",
    "\n",
    "\n",
    "       xinter_grid = generate(emb1, emb2, interpolations)\n",
    "       image_acc = torch.concat((image_acc, xinter_grid))\n",
    "\n",
    "fig = create_visualization(image_acc, trait, analysis_group)\n",
    "plt.show(fig)\n",
    "fig.savefig(f'{outdir}/{trait}_interpolation_{analysis_group}.png', dpi=150)\n",
    "\n",
    "\n",
    "\n",
    "#plt.title(f'{trait} interpolation Day {day} TCF7L2_ko')\n",
    "\n",
    "# emb1 = dfX_30_embeddings.iloc[np.where(dfX_30_embeddings[Il1][trait] == min(dfX_30_embeddings[Il1][trait]))].values\n",
    "# emb2 = dfX_30_embeddings.iloc[np.where(dfX_30_embeddings[Ih1][trait] == max(dfX_30_embeddings[Ih1][trait]))].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33039cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
